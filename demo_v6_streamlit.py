import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, _tree, plot_tree
from matplotlib.colors import ListedColormap
import matplotlib.patches as mpatches
import copy

# --- 0. Cáº¥u hÃ¬nh trang Streamlit ---
st.set_page_config(layout="wide", page_title="Minh Há»a CÃ¢y Quyáº¿t Äá»‹nh")
st.title("ğŸŒ³ Minh Há»a Tá»«ng BÆ°á»›c Thuáº­t ToÃ¡n CÃ¢y Quyáº¿t Äá»‹nh")
st.markdown("---")

# --- 1. Táº¡o bá»™ dá»¯ liá»‡u Vá»ŠT - GÃ€ ---
@st.cache_data
def get_data():
    np.random.seed(42)
    vit_mo_dai = np.random.uniform(low=2.8, high=4.5, size=(10, 1))
    vit_chan_da_dang = np.random.uniform(low=1.5, high=5.0, size=(10, 1))
    data_vit_1 = np.hstack((vit_mo_dai, vit_chan_da_dang))
    vit_mo_ngan_chan_dai = np.random.uniform(low=1.0, high=2.5, size=(5, 1))
    vit_chan_rat_dai = np.random.uniform(low=4.0, high=5.5, size=(5, 1))
    data_vit_2 = np.hstack((vit_mo_ngan_chan_dai, vit_chan_rat_dai))
    data_vit = np.vstack((data_vit_1, data_vit_2))
    labels_vit = np.zeros(data_vit.shape[0]) # 0 = Vá»‹t

    ga_mo_ngan = np.random.uniform(low=0.8, high=2.7, size=(12, 1))
    ga_chan_ngan_vua = np.random.uniform(low=1.0, high=3.8, size=(12, 1))
    data_ga_1 = np.hstack((ga_mo_ngan, ga_chan_ngan_vua))
    ga_mo_rat_ngan = np.random.uniform(low=0.5, high=1.5, size=(4,1))
    ga_chan_rat_ngan = np.random.uniform(low=0.8, high=2.0, size=(4,1))
    data_ga_2 = np.hstack((ga_mo_rat_ngan, ga_chan_rat_ngan))
    data_ga = np.vstack((data_ga_1, data_ga_2))
    labels_ga = np.ones(data_ga.shape[0]) # 1 = GÃ 

    X_original = np.vstack((data_vit, data_ga))
    y_original = np.concatenate((labels_vit, labels_ga))
    return X_original, y_original

X_original, y_original = get_data()
feature_names = ['Äá»™ dÃ i má» (cm)', 'Chiá»u dÃ i chÃ¢n (cm)']
class_names = ['Vá»‹t', 'GÃ ']
colors_plot = ['#FF0000', '#0000FF'] # Red for Vit (0), Blue for Ga (1)
cmap_custom = ListedColormap(colors_plot)


# --- 2. Huáº¥n luyá»‡n mÃ´ hÃ¬nh ---
def on_slider_change_callback():
    st.session_state.max_depth_slider_changed_flag = True

MAX_DEPTH_DEMO = st.sidebar.slider("Chá»n Ä‘á»™ sÃ¢u tá»‘i Ä‘a cho cÃ¢y demo:", 1, 5, 3, key="max_depth_slider", on_change=on_slider_change_callback)

@st.cache_resource
def train_tree(_X, _y, max_depth):
    dt_classifier = DecisionTreeClassifier(criterion="gini", random_state=42, max_depth=max_depth)
    dt_classifier.fit(_X, _y)
    return dt_classifier

# Re-train tree if max_depth changes or on first run
# This check ensures the cached resource updates correctly when MAX_DEPTH_DEMO changes
if 'trained_max_depth' not in st.session_state or st.session_state.trained_max_depth != MAX_DEPTH_DEMO:
    dt_classifier = train_tree(X_original, y_original, MAX_DEPTH_DEMO)
    st.session_state.trained_max_depth = MAX_DEPTH_DEMO # Store the depth it was trained with
    # Clear potentially outdated state if tree structure changes
    if 'current_nodes_to_process' in st.session_state:
        initialize_state_logic(force_rerun=True)
else:
    # Retrieve from cache if depth hasn't changed since last train_tree call
    dt_classifier = train_tree(X_original, y_original, MAX_DEPTH_DEMO)

tree_ = dt_classifier.tree_


# --- Helper Function for Gini Calculation String ---
def format_gini_calculation(node_value_array, total_samples):
    """Formats a string explaining the Gini calculation for a node."""
    if total_samples == 0:
        return " (KhÃ´ng cÃ³ máº«u)"
    gini_calc_str = "`1 - Î£(p_i)^2 = 1 - ("
    terms = []
    for i, count in enumerate(node_value_array):
        proportion = count / total_samples
        # Showing counts/total makes the calculation clearer
        terms.append(f"({int(count)}/{total_samples})^2")
        # Or show proportions: terms.append(f"{proportion:.3f}^2")
    gini_calc_str += " + ".join(terms) + ")`"
    return gini_calc_str

# --- 3. Khá»Ÿi táº¡o/Reset Session State ---
def initialize_state_logic(force_rerun=False):
    st.session_state.current_nodes_to_process = [(0, X_original.copy(), y_original.copy(), 0, None)]
    st.session_state.history = [] # Stores (plot_args, info_text, nodes_to_process_before, step_val_before, node_id_displayed_before)
    st.session_state.step_counter = 0
    st.session_state.finished_processing = False
    st.session_state.max_depth_slider_changed_flag = False # Reset flag after use
    st.session_state.current_plot_args_cache = None
    st.session_state.processed_nodes = [] # Keep track of processed nodes if needed for other features

    # Initial info text for Step 0
    node_id = 0
    node_value_array = tree_.value[node_id][0]
    total_samples = tree_.n_node_samples[node_id]
    gini_value = tree_.impurity[node_id]
    gini_calc_explanation = format_gini_calculation(node_value_array, total_samples)
    root_counts_str = ", ".join([f"{class_names[i]}: {int(node_value_array[i])}" for i in range(len(class_names))])

    st.session_state.current_info_text_cache = (
        f"**BÆ°á»›c {st.session_state.step_counter}: Xem xÃ©t NÃºt Gá»‘c `0` (Äá»™ sÃ¢u 0)**\n"
        f"- **Tá»•ng sá»‘ máº«u:** {total_samples} \n"
        f"- **Gini impurity:** `{gini_value:.3f}` {gini_calc_explanation}\n"
    )
    if gini_value == 0.0:
        st.session_state.current_info_text_cache += "- *NÃºt Ä‘Ã£ thuáº§n khiáº¿t!*\n"

    st.session_state.current_info_text_cache += f"\nâ¡ï¸ **Nháº¥n 'BÆ°á»›c Tiáº¿p Theo' Ä‘á»ƒ báº¯t Ä‘áº§u xÃ¢y dá»±ng cÃ¢y.**"


    # Initial plot args cache for Step 0
    root_feature_idx = None
    root_threshold = None
    # Show potential split line even at step 0 if root node isn't a leaf
    if tree_.children_left[0] != _tree.TREE_LEAF and 0 < MAX_DEPTH_DEMO:
        root_feature_idx = tree_.feature[0]
        root_threshold = tree_.threshold[0]

    st.session_state.current_plot_args_cache = {
        'X_node_data': X_original.copy(), 'y_node_data': y_original.copy(),
        'title': f"BÆ°á»›c 0: Dá»¯ liá»‡u gá»‘c (NÃºt 0)",
        'parent_split_info': None,
        'feature_idx': root_feature_idx, # Show potential split
        'threshold': root_threshold     # Show potential split
    }
    st.session_state.current_node_id_being_displayed = 0

    if force_rerun:
        st.rerun()

# Initialize state on first run or if slider changed
if 'current_nodes_to_process' not in st.session_state or st.session_state.get('max_depth_slider_changed_flag', False):
    # Set flag to false *before* initializing to prevent loop if init fails
    if 'max_depth_slider_changed_flag' in st.session_state:
         st.session_state.max_depth_slider_changed_flag = False
    initialize_state_logic(force_rerun=True) # Force rerun on init/slider change

# --- 4. HÃ m trá»£ giÃºp Ä‘á»ƒ váº½ ---

# plot_data_at_node_streamlit remains the same as your last version
def plot_data_at_node_streamlit(ax, X_node_data, y_node_data, title, feature_idx=None, threshold=None, parent_split_info=None):
    ax.clear()
    unique_classes = np.unique(y_node_data)
    for class_label in unique_classes:
        mask = y_node_data == class_label
        ax.scatter(X_node_data[mask, 0], X_node_data[mask, 1],
                   c=colors_plot[int(class_label)],
                   label=class_names[int(class_label)],
                   edgecolor='k', s=80, alpha=0.8)

    ax.set_xlabel(feature_names[0])
    ax.set_ylabel(feature_names[1])
    counts = np.bincount(y_node_data.astype(int), minlength=len(class_names))
    class_counts_str = ", ".join([f"{class_names[i]}: {counts[i]}" for i in range(len(class_names))])
    ax.set_title(f"{title}\n{class_counts_str}", fontsize=10)
    ax.grid(True)
    xlim = (X_original[:,0].min()-0.5, X_original[:,0].max()+0.5)
    ylim = (X_original[:,1].min()-0.5, X_original[:,1].max()+0.5)
    ax.set_xlim(xlim)
    ax.set_ylim(ylim)
    ax.legend(loc='lower right', title="LoÃ i")

    if parent_split_info:
        p_feature, p_threshold, p_direction = parent_split_info
        line_style, line_color, fill_alpha = ':', 'gray', 0.1
        if p_feature == 0:
            ax.axvline(p_threshold, color=line_color, linestyle=line_style, linewidth=1.5)
            if p_direction == 'left': ax.fill_betweenx(ylim, xlim[0], p_threshold, color=line_color, alpha=fill_alpha)
            else: ax.fill_betweenx(ylim, p_threshold, xlim[1], color=line_color, alpha=fill_alpha)
        else:
            ax.axhline(p_threshold, color=line_color, linestyle=line_style, linewidth=1.5)
            if p_direction == 'left': ax.fill_between(xlim, ylim[0], p_threshold, color=line_color, alpha=fill_alpha)
            else: ax.fill_between(xlim, p_threshold, ylim[1], color=line_color, alpha=fill_alpha)

    if feature_idx is not None and threshold is not None:
        line_style, line_color = '--', 'green'
        if feature_idx == 0:
            ax.axvline(threshold, color=line_color, linestyle=line_style, linewidth=2)
            ax.text(threshold + 0.05, ylim[1] - 0.1, f'{feature_names[feature_idx]}\n<= {threshold:.2f}?', color=line_color, rotation=0, va='top', ha='left', fontsize=8, bbox=dict(facecolor='white', alpha=0.5, pad=0.1))
        else:
            ax.axhline(threshold, color=line_color, linestyle=line_style, linewidth=2)
            ax.text(xlim[1] - 0.1, threshold + 0.05, f'{feature_names[feature_idx]}\n<= {threshold:.2f}?', color=line_color, va='bottom', ha='right', fontsize=8, bbox=dict(facecolor='white', alpha=0.5, pad=0.1))
    return plt.gcf()

# --- HÃ m váº½ cÃ¢y Ä‘Ã£ Ä‘Æ°á»£c sá»­a Ä‘á»•i ---
def create_full_tree_plot_figure(dt_classifier_obj, f_names, c_names):
    """Creates a Matplotlib Figure object containing the full decision tree plot."""
    # --- TÄ‚NG CÃC GIÃ TRá»Š á» ÄÃ‚Y ---
    fig_tree, ax = plt.subplots(figsize=(8, 6)) # TÄƒng kÃ­ch thÆ°á»›c tá»•ng thá»ƒ (vÃ­ dá»¥: 35x20 inches)
    plot_tree(dt_classifier_obj,
              ax=ax,
              filled=True,
              feature_names=f_names,
              class_names=c_names,
              rounded=True,
              fontsize=14, # TÄƒng kÃ­ch thÆ°á»›c chá»¯ (vÃ­ dá»¥: 14)
              impurity=True,
              proportion=False,
              node_ids=True,
              label='all'
             )
   
    # --- Káº¾T THÃšC PHáº¦N TÄ‚NG GIÃ TRá»Š ---
    plt.tight_layout() # Cá»‘ gáº¯ng Ä‘iá»u chá»‰nh bá»‘ cá»¥c
    return fig_tree
# --- Háº¾T HÃ€M Sá»¬A Äá»”I ---

# --- 5. Giao diá»‡n vÃ  Logic chÃ­nh ---
# Adjust column ratio to give more space for info/queue
col_main, col_sidebar = st.columns([2, 2]) # e.g., 40% for info, 60% for tree

with col_main:
    st.subheader("ThÃ´ng Tin BÆ°á»›c XÃ¢y Dá»±ng CÃ¢y")
    info_placeholder = st.empty()
    st.markdown("---")
    st.subheader("Biá»ƒu Äá»“ Dá»¯ Liá»‡u Táº¡i NÃºt")
    plot_placeholder = st.empty()
    st.markdown("---")
    st.subheader("HÃ ng Äá»£i CÃ¡c NÃºt Cáº§n Xá»­ LÃ½") # Added Header for Queue
    queue_placeholder = st.empty() # Placeholder for Queue info

with col_sidebar:
    st.subheader("CÃ¢y Quyáº¿t Äá»‹nh HoÃ n Chá»‰nh")
    tree_plot_placeholder = st.empty()
    st.markdown("---")
    st.sidebar.markdown("### Äiá»u Khiá»ƒn")

# --- Button Logic ---
button_cols = st.sidebar.columns(2)
with button_cols[0]:
    prev_disabled = not st.session_state.history
    if st.button("â¬…ï¸ BÆ°á»›c TrÆ°á»›c", key="prev_step_btn", disabled=prev_disabled, use_container_width=True):
        if st.session_state.history:
            # Pop state: (plot_args, info_text, nodes_to_process_before, step_val_before, node_id_displayed_before)
            (prev_plot_args, prev_info_text, prev_nodes_to_process,
             prev_step_val, prev_node_id_displayed) = st.session_state.history.pop()

            # Restore state
            st.session_state.current_plot_args_cache = prev_plot_args
            st.session_state.current_info_text_cache = prev_info_text
            st.session_state.current_nodes_to_process = prev_nodes_to_process
            st.session_state.step_counter = prev_step_val
            st.session_state.current_node_id_being_displayed = prev_node_id_displayed
            st.session_state.finished_processing = False

            # Rerun to update display
            st.rerun()

with button_cols[1]:
    next_disabled = st.session_state.finished_processing or not st.session_state.current_nodes_to_process
    if st.button("â¡ï¸ BÆ°á»›c Tiáº¿p Theo", key="next_step_btn", type="primary", disabled=next_disabled, use_container_width=True):
        if st.session_state.current_nodes_to_process:
            # --- Save State BEFORE processing ---
            nodes_to_process_before_pop = copy.deepcopy(st.session_state.current_nodes_to_process)
            # No need to save processed_nodes for this display logic
            st.session_state.history.append((
                copy.deepcopy(st.session_state.current_plot_args_cache),
                st.session_state.current_info_text_cache,
                nodes_to_process_before_pop,
                st.session_state.step_counter,
                st.session_state.current_node_id_being_displayed
            ))

            # --- Process Node ---
            node_id, X_subset, y_subset, depth, parent_split_info_for_current_node = st.session_state.current_nodes_to_process.pop(0)
            st.session_state.step_counter += 1
            st.session_state.current_node_id_being_displayed = node_id

            if node_id not in st.session_state.processed_nodes:
                st.session_state.processed_nodes.append(node_id)

            # --- Gather Info for Current Node ---
            is_leaf_in_tree = (tree_.children_left[node_id] == _tree.TREE_LEAF)
            is_leaf_due_to_depth = (depth >= MAX_DEPTH_DEMO)
            is_leaf = is_leaf_in_tree or is_leaf_due_to_depth

            node_value = tree_.value[node_id][0]
            total_samples = tree_.n_node_samples[node_id]
            gini_value = tree_.impurity[node_id]
            predicted_class_idx = np.argmax(node_value)
            predicted_class_name = class_names[predicted_class_idx]
            gini_calc_explanation = format_gini_calculation(node_value, total_samples)
            node_counts_str = ", ".join([f"{class_names[i]}: {int(node_value[i])}" for i in range(len(class_names))])

            # --- Build Info Text ---
            current_title_plot = f"BÆ°á»›c {st.session_state.step_counter}: XÃ©t NÃºt `{node_id}` (SÃ¢u {depth})"
            current_info_text = f"**{current_title_plot}**\n"
            current_info_text += f"- **Tá»•ng sá»‘ máº«u:** {total_samples} \n"
            current_info_text += f"- **Gini impurity:** `{gini_value:.3f}` {gini_calc_explanation}\n"
            if gini_value == 0.0:
                 current_info_text += "- *NÃºt thuáº§n khiáº¿t!*\n"


            # --- Prepare Plot Arguments ---
            plot_args_current = {
                'X_node_data': X_subset.copy(), 'y_node_data': y_subset.copy(),
                'title': current_title_plot.replace("XÃ©t", "Dá»¯ liá»‡u táº¡i"), # Adjust title for plot
                'parent_split_info': parent_split_info_for_current_node,
                'feature_idx': None, # Default for leaf
                'threshold': None  # Default for leaf
            }

            # --- Handle Leaf vs. Split ---
            if is_leaf:
                leaf_reason = "(Do Ä‘á»™ sÃ¢u tá»‘i Ä‘a)" if is_leaf_due_to_depth and not is_leaf_in_tree else ""
                current_info_text += f"- **==> NÃšT LÃ** {leaf_reason}. **Dá»± Ä‘oÃ¡n:** `{predicted_class_name}`\n"
                # plot_args already set for leaf
            else:
                # Node is being split
                feature = tree_.feature[node_id]
                threshold = tree_.threshold[node_id]
                left_child_id = tree_.children_left[node_id]
                right_child_id = tree_.children_right[node_id]

                current_info_text += f"- **Quyáº¿t Ä‘á»‹nh chia:** `{feature_names[feature]}` <= `{threshold:.2f}` ?\n"
                plot_args_current.update({'feature_idx': feature, 'threshold': threshold}) # Update plot args for split line

                # Calculate child node data
                left_mask = X_subset[:, feature] <= threshold
                right_mask = X_subset[:, feature] > threshold
                X_left, y_left = X_subset[left_mask], y_subset[left_mask]
                X_right, y_right = X_subset[right_mask], y_subset[right_mask]

                # Get info for children to display in text and potentially add to queue
                if left_child_id != _tree.TREE_LEAF:
                    left_value = tree_.value[left_child_id][0]
                    left_samples = tree_.n_node_samples[left_child_id] # Samples *in child node* from training
                    left_gini = tree_.impurity[left_child_id]
                    left_counts_str = ", ".join([f"{cl}: {int(v)}" for cl, v in zip(class_names, left_value)])
                    current_info_text += f"  - **NhÃ¡nh TRÃI (True):** -> NÃºt `{left_child_id}` ({X_left.shape[0]} máº«u Ä‘i vÃ o, Gini nÃºt con: {left_gini:.3f}, Counts: [{left_counts_str}])\n"
                    # Add to queue if it's not a leaf by depth
                    if (depth + 1) < MAX_DEPTH_DEMO and X_left.shape[0] > 0:
                         st.session_state.current_nodes_to_process.append((left_child_id, X_left, y_left, depth + 1, (feature, threshold, 'left')))
                    elif (depth + 1) >= MAX_DEPTH_DEMO and left_child_id not in st.session_state.processed_nodes:
                        st.session_state.processed_nodes.append(left_child_id) # Mark as processed if leaf due to depth

                if right_child_id != _tree.TREE_LEAF:
                    right_value = tree_.value[right_child_id][0]
                    right_samples = tree_.n_node_samples[right_child_id]
                    right_gini = tree_.impurity[right_child_id]
                    right_counts_str = ", ".join([f"{cl}: {int(v)}" for cl, v in zip(class_names, right_value)])
                    current_info_text += f"  - **NhÃ¡nh PHáº¢I (False):** -> NÃºt `{right_child_id}` ({X_right.shape[0]} máº«u Ä‘i vÃ o, Gini nÃºt con: {right_gini:.3f}, Counts: [{right_counts_str}])\n"
                    # Add to queue if it's not a leaf by depth
                    if (depth + 1) < MAX_DEPTH_DEMO and X_right.shape[0] > 0:
                         st.session_state.current_nodes_to_process.append((right_child_id, X_right, y_right, depth + 1, (feature, threshold, 'right')))
                    elif (depth + 1) >= MAX_DEPTH_DEMO and right_child_id not in st.session_state.processed_nodes:
                        st.session_state.processed_nodes.append(right_child_id) # Mark as processed if leaf due to depth


            # --- Update Cache for next display cycle ---
            st.session_state.current_plot_args_cache = plot_args_current
            st.session_state.current_info_text_cache = current_info_text

        # --- Check Finish Condition ---
        if not st.session_state.current_nodes_to_process and not st.session_state.finished_processing:
            st.session_state.finished_processing = True
            # Append completion message to the *cached* info text
            st.session_state.current_info_text_cache += "\n\nğŸ‰ **HoÃ n thÃ nh xÃ¢y dá»±ng cÃ¢y (Ä‘áº¿n Ä‘á»™ sÃ¢u tá»‘i Ä‘a)!** ğŸ‰"

        # --- Rerun ---
        st.rerun()


# --- Display Current State (runs on each interaction/rerun) ---

# 1. Display Info Text (always uses cache)
info_placeholder.markdown(st.session_state.current_info_text_cache, unsafe_allow_html=True) # Allow markdown formatting like backticks

# 2. Display Data Plot (uses cache)
if st.session_state.current_plot_args_cache is not None:
    fig_main_display, ax_main_display = plt.subplots(figsize=(7, 6)) # Adjust size if needed
    plot_data_at_node_streamlit(ax_main_display, **st.session_state.current_plot_args_cache)
    plot_placeholder.pyplot(fig_main_display)
    plt.close(fig_main_display)

# 3. Display Queue Info (calculated fresh each time)
queue_info_text = "" # Start fresh
if st.session_state.current_nodes_to_process:
    # Sort queue for consistent display (by depth, then node ID)
    sorted_queue = sorted(st.session_state.current_nodes_to_process, key=lambda x: (x[3], x[0]))
    queue_info_text += "**CÃ¡c nÃºt Ä‘ang chá» xá»­ lÃ½ (Sáº¯p xáº¿p theo Ä‘á»™ sÃ¢u, ID):**\n"
    for q_node_id, q_X_sub, _, q_depth, _ in sorted_queue:
        q_samples = q_X_sub.shape[0]
        q_gini = tree_.impurity[q_node_id]
        queue_info_text += f"- **NÃºt `{q_node_id}`**: SÃ¢u `{q_depth}`, `{q_samples}` máº«u, Gini `{q_gini:.3f}`\n"
elif st.session_state.finished_processing:
    queue_info_text += "_HÃ ng Ä‘á»£i trá»‘ng (ÄÃ£ hoÃ n thÃ nh xÃ¢y dá»±ng cÃ¢y)_"
elif st.session_state.step_counter > 0: # Don't show empty queue at step 0 start
     queue_info_text += "_HÃ ng Ä‘á»£i trá»‘ng_"
# Only display the queue text if there's something to show or it's finished
if queue_info_text:
    queue_placeholder.markdown(queue_info_text)
else:
     # Clear the placeholder if queue is conceptually empty at start
     queue_placeholder.empty()


# 4. Display Full Tree Plot (regenerated each time)
fig_tree_display = create_full_tree_plot_figure(
    dt_classifier,
    feature_names,
    class_names
)
tree_plot_placeholder.pyplot(fig_tree_display)
plt.close(fig_tree_display) # Close immediately


# --- Reset Button ---
if st.sidebar.button("ğŸ”„ Reset Demo", key="reset_all_btn", use_container_width=True):
    # Clear cache associated with the specific training function if needed
    # train_tree.clear() # Usually not necessary unless hitting specific caching issues
    initialize_state_logic(force_rerun=True)


st.sidebar.markdown("---")
st.sidebar.header("ChÃº Giáº£i")
st.sidebar.markdown("""
**ThÃ´ng Tin BÆ°á»›c (TrÃ¡i - TrÃªn):**
- **Sá»‘ máº«u:** Tá»•ng sá»‘ máº«u táº¡i nÃºt Ä‘ang xÃ©t vÃ  sá»‘ lÆ°á»£ng má»—i lá»›p [Vá»‹t, GÃ ].
- **Gini impurity:** Äá»™ Ä‘o má»©c Ä‘á»™ "láº«n lá»™n" cá»§a cÃ¡c lá»›p táº¡i nÃºt.
    - CÃ´ng thá»©c: `1 - Î£(p_i)^2`, vá»›i `p_i` lÃ  tá»· lá»‡ máº«u cá»§a lá»›p `i`.
    - Gini = 0.0 nghÄ©a lÃ  nÃºt hoÃ n toÃ n thuáº§n khiáº¿t (chá»‰ chá»©a 1 lá»›p).
- **Quyáº¿t Ä‘á»‹nh chia:** Náº¿u nÃºt khÃ´ng pháº£i lÃ¡, hiá»ƒn thá»‹ Ä‘áº·c trÆ°ng vÃ  ngÆ°á»¡ng dÃ¹ng Ä‘á»ƒ chia.
- **NhÃ¡nh TRÃI/PHáº¢I:** ThÃ´ng tin vá» nÃºt con káº¿t quáº£, bao gá»“m sá»‘ máº«u Ä‘i vÃ o nhÃ¡nh Ä‘Ã³, Gini cá»§a nÃºt con, vÃ  sá»‘ lÆ°á»£ng máº«u má»—i lá»›p táº¡i nÃºt con.

**Biá»ƒu Äá»“ Dá»¯ Liá»‡u (TrÃ¡i - Giá»¯a):**
- Hiá»ƒn thá»‹ cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u thuá»™c vá» nÃºt Ä‘ang xÃ©t.
- ÄÆ°á»ng nÃ©t Ä‘á»©t mÃ u xanh lÃ¡: ÄÆ°á»ng phÃ¢n chia Ä‘Æ°á»£c quyáº¿t Ä‘á»‹nh táº¡i nÃºt nÃ y (náº¿u cÃ³).
- VÃ¹ng tÃ´ xÃ¡m nháº¡t: KhÃ´ng gian dá»¯ liá»‡u cá»§a nÃºt cha (náº¿u cÃ³).

**HÃ ng Äá»£i (TrÃ¡i - DÆ°á»›i):**
- Liá»‡t kÃª cÃ¡c nÃºt Ä‘ang chá» Ä‘Æ°á»£c xá»­ lÃ½ theo thá»© tá»± Æ°u tiÃªn (thÆ°á»ng lÃ  theo chiá»u rá»™ng - Breadth-First).

**CÃ¢y Quyáº¿t Äá»‹nh (Pháº£i):**
- Hiá»ƒn thá»‹ cáº¥u trÃºc cÃ¢y *hoÃ n chá»‰nh* Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i Ä‘á»™ sÃ¢u tá»‘i Ä‘a Ä‘Ã£ chá»n.
- **samples**: Tá»•ng sá»‘ máº«u táº¡i nÃºt (trong dá»¯ liá»‡u huáº¥n luyá»‡n ban Ä‘áº§u).
- **value**: Sá»‘ lÆ°á»£ng máº«u má»—i lá»›p [Vá»‹t, GÃ ] táº¡i nÃºt.
- **class**: Lá»›p dá»± Ä‘oÃ¡n Ä‘a sá»‘ táº¡i nÃºt.
- **gini**: Gini impurity cá»§a nÃºt.
""")
st.sidebar.markdown("---")
st.sidebar.info("Äiá»u chá»‰nh 'Äá»™ sÃ¢u tá»‘i Ä‘a' hoáº·c nháº¥n 'ğŸ”„ Reset Demo' sáº½ báº¯t Ä‘áº§u láº¡i.")